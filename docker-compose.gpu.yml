services:
  celery_worker:
    build:
      context: .  # Keep the build context as the root directory
      dockerfile: docker/Dockerfile.gpu.distributed-server  # Specify the new path to the GPU Dockerfile
    command: celery -A marker_api.celery_worker.celery_app worker --pool=solo --loglevel=info
    image: marker-api-gpu
    volumes:
      - .:/app
    environment:
      - REDIS_HOST=${REDIS_HOST}
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # Request GPU support

  app:
    container_name: marker-api-gpu
    image: marker-api-gpu
    command: python distributed_server.py --host 0.0.0.0 --port 8010
    environment:
      - ENV=production
    ports:
      - "8010:8010"
    volumes:
      - .:/app
    depends_on:
      - celery_worker
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # Request GPU support

  sentence_text_embedding:
    build:
      context: .
      dockerfile: docker/Dockerfile.gpu.sentence-text-embedding-server
    image: sentence-text-embedding-gpu
    command: uvicorn sentence_text_embedding:app --host 0.0.0.0 --port 8020 --workers 3
    environment:
      - ENV=production
      - CUDA_VISIBLE_DEVICES=1
    ports:
      - "8020:8020"
    volumes:
    - .:/app
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
  
  image_embedding:
    build:
      context: .
      dockerfile: docker/Dockerfile.gpu.image-embedding-server
    image: image-embedding-gpu
    command: uvicorn image_embedding:app --host 0.0.0.0 --port 8030 --workers 3
    environment:
      - ENV=production
      - CUDA_VISIBLE_DEVICES=1
    ports:
      - "8030:8030"
    volumes:
      - .:/app
    deploy:
      resources:
        reservations:
          devices:
          - capabilities: [gpu]

  flower:
    container_name: flower_gpu
    image: marker-api-gpu
    command: celery -A marker_api.celery_worker.celery_app flower --port=5555
    ports:
      - 5556:5555
    volumes:
      - .:/app
    environment:
      - REDIS_HOST=${REDIS_HOST}
    depends_on:
      - app
      - celery_worker
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # Request GPU support
  
  tika:
    image: openjdk:11-slim
    working_dir: /app
    command: ["java", "-jar", "tika-server-standard-2.9.2.jar", "--host", "0.0.0.0", "--port=9998"]
    ports:
      - "9998:9998"
    volumes:
      - ./tika:/app